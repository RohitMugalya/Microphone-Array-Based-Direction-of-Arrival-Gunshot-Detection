{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from qbstyles import mpl_style\n",
    "\n",
    "mpl_style()\n",
    "\n",
    "# Constants\n",
    "SPEED_OF_SOUND = 343.0  # m/s\n",
    "MIC_POSITIONS = np.array([  # Hexagonal array (6 mics, 3D coordinates)\n",
    "    [0.0, 0.0, 0.0],      # Mic 1 (center)\n",
    "    [1.5, 0.0, 0.0],      # Mic 2 (right)\n",
    "    [0.75, 1.299, 0.0],   # Mic 3 (top-right)\n",
    "    [-0.75, 1.299, 0.0],  # Mic 4 (top-left)\n",
    "    [-1.5, 0.0, 0.0],     # Mic 5 (left)\n",
    "    [-0.75, -1.299, 0.0]  # Mic 6 (bottom-left)\n",
    "]).T  # Shape: (3, 6)\n",
    "\n",
    "DATA_DIR = \"../data/simulations/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading & pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (80, 44100, 6), Test shape: (20, 44100, 6)\n"
     ]
    }
   ],
   "source": [
    "def load_waveforms(sim_dir, max_length=44100):\n",
    "    \"\"\"Load and pad/truncate 6-mic waveforms to max_length.\"\"\"\n",
    "    recordings = []\n",
    "    for mic in range(1, 7):\n",
    "        audio, _ = librosa.load(f\"{sim_dir}/mic_{mic}_recording.wav\", sr=None)\n",
    "        if len(audio) > max_length:\n",
    "            audio = audio[:max_length]\n",
    "        else:\n",
    "            audio = np.pad(audio, (0, max_length - len(audio)))\n",
    "        recordings.append(audio)\n",
    "    return np.stack(recordings, axis=1)  # Shape: (max_length, 6)\n",
    "\n",
    "# Load all simulations\n",
    "labels = pd.read_csv(f\"{DATA_DIR}/labels.csv\")\n",
    "X = np.array([load_waveforms(f\"{DATA_DIR}/gunshot_{i}\") for i in range(len(labels))])\n",
    "y = labels[[\"distance\", \"azimuth\", \"elevation\"]].values\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Physics Informed Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def physics_loss(y_true, y_pred):\n",
    "    \"\"\"Penalize deviations from TDoA physics.\"\"\"\n",
    "    # Predicted polar coordinates\n",
    "    distance, azimuth, elevation = y_pred[:, 0], y_pred[:, 1], y_pred[:, 2]\n",
    "    \n",
    "    # Convert to Cartesian (relative to Mic1)\n",
    "    x = distance * np.cos(azimuth) * np.cos(elevation)\n",
    "    y = distance * np.sin(azimuth) * np.cos(elevation)\n",
    "    z = distance * np.sin(elevation)\n",
    "    source_pos = tf.stack([x, y, z], axis=1)  # Shape: (batch, 3)\n",
    "    \n",
    "    # Calculate expected TDoA (mic1 as reference)\n",
    "    mic1_pos = tf.constant(MIC_POSITIONS[:, 0], dtype=tf.float32)\n",
    "    mic_positions = tf.constant(MIC_POSITIONS, dtype=tf.float32)  # (3, 6)\n",
    "    distances = tf.norm(mic_positions - tf.expand_dims(source_pos, 2), axis=1)  # (batch, 6)\n",
    "    tdoa_pred = (distances - tf.expand_dims(distances[:, 0], 1)) / SPEED_OF_SOUND  # (batch, 6)\n",
    "    \n",
    "    # Ground truth TDoA (from waveforms)\n",
    "    tdoa_true = tf.py_function(\n",
    "        lambda x: np.array([[\n",
    "            np.argmax(signal.correlate(x[i, :, 0], x[i, :, j])) - len(x[i, :, 0])\n",
    "            for j in range(6)] for i in range(x.shape[0])]) / SAMPLE_RATE,\n",
    "        [X], tf.float32\n",
    "    )\n",
    "    \n",
    "    return tf.reduce_mean((tdoa_true[:, 1:] - tdoa_pred[:, 1:])**2)  # Skip mic1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PINN model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44086</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11021</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11015</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">57,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44086\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │         \u001b[38;5;34m5,824\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11021\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11015\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m57,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,195</span> (313.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m80,195\u001b[0m (313.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,195</span> (313.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m80,195\u001b[0m (313.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_pinn(input_shape):\n",
    "    \"\"\"Waveform-based PINN for gunshot localization.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),  # (None, 6)\n",
    "        layers.Conv1D(64, 15, activation='relu'),\n",
    "        layers.MaxPooling1D(4),\n",
    "        layers.Conv1D(128, 7, activation='relu'),\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(3)  # distance, azimuth, elevation\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_pinn((X_train.shape[1], 6))\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINNTrainer(tf.keras.Model):\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)\n",
    "            mse_loss = self.compiled_loss(y, y_pred)\n",
    "            phys_loss = physics_loss(y, y_pred)\n",
    "            total_loss = mse_loss + 0.1 * phys_loss  # Weighted sum\n",
    "        grads = tape.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        return {\"loss\": total_loss, \"mse\": mse_loss, \"physics_loss\": phys_loss}\n",
    "\n",
    "trainer = PINNTrainer(model)\n",
    "history = trainer.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Distance error (meters)\n",
    "    distance_error = np.abs(y_pred[:, 0] - y_test[:, 0])\n",
    "    \n",
    "    # Angular error (degrees)\n",
    "    azimuth_error = np.degrees(np.abs(y_pred[:, 1] - y_test[:, 1]))\n",
    "    elevation_error = np.degrees(np.abs(y_pred[:, 2] - y_test[:, 2]))\n",
    "    \n",
    "    # 3D position error (meters)\n",
    "    def polar_to_cartesian(r, theta, phi):\n",
    "        x = r * np.cos(theta) * np.cos(phi)\n",
    "        y = r * np.sin(theta) * np.cos(phi)\n",
    "        z = r * np.sin(phi)\n",
    "        return np.stack([x, y, z], axis=1)\n",
    "    \n",
    "    pos_true = polar_to_cartesian(y_test[:, 0], y_test[:, 1], y_test[:, 2])\n",
    "    pos_pred = polar_to_cartesian(y_pred[:, 0], y_pred[:, 1], y_pred[:, 2])\n",
    "    position_error = np.linalg.norm(pos_true - pos_pred, axis=1)\n",
    "    \n",
    "    print(f\"Mean Distance Error: {np.mean(distance_error):.2f} m\")\n",
    "    print(f\"Mean Azimuth Error: {np.mean(azimuth_error):.2f}°\")\n",
    "    print(f\"Mean Elevation Error: {np.mean(elevation_error):.2f}°\")\n",
    "    print(f\"Mean 3D Position Error: {np.mean(position_error):.2f} m\")\n",
    "\n",
    "evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['mse'], label='Train MSE')\n",
    "plt.plot(history.history['val_mse'], label='Val MSE')\n",
    "plt.xlabel('Epoch'); plt.ylabel('MSE'); plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['physics_loss'], label='Physics Loss')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
